{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "example_one_bundesland.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Patrick5455/Change-Point-Analysis-of-Covid19-Bayesian-Inference-SIR-SEIR-Modelling/blob/master/dependencies/covid19_inference-master/scripts/interactive/example_one_bundesland.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bCy-f_xa_Cv",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Priesemann-Group/covid19_inference/blob/model_cleanup/scripts/interactive/example_one_bundesland.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQw7UNXua_C0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "f62f67df-71e7-4e61-fb09-f08df532d1ec"
      },
      "source": [
        "!pip install git+https://github.com/Priesemann-Group/covid19_inference.git"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/Priesemann-Group/covid19_inference.git\n",
            "  Cloning https://github.com/Priesemann-Group/covid19_inference.git to /tmp/pip-req-build-5m15iiar\n",
            "  Running command git clone -q https://github.com/Priesemann-Group/covid19_inference.git /tmp/pip-req-build-5m15iiar\n",
            "Requirement already satisfied (use --upgrade to upgrade): covid19-inference==0.1.8a0 from git+https://github.com/Priesemann-Group/covid19_inference.git in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: pymc3 in /usr/local/lib/python3.6/dist-packages (from covid19-inference==0.1.8a0) (3.7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from covid19-inference==0.1.8a0) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from covid19-inference==0.1.8a0) (1.18.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from covid19-inference==0.1.8a0) (1.0.5)\n",
            "Requirement already satisfied: theano in /usr/local/lib/python3.6/dist-packages (from covid19-inference==0.1.8a0) (1.0.5)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from pymc3->covid19-inference==0.1.8a0) (0.5.1)\n",
            "Requirement already satisfied: tqdm>=4.8.4 in /usr/local/lib/python3.6/dist-packages (from pymc3->covid19-inference==0.1.8a0) (4.41.1)\n",
            "Requirement already satisfied: h5py>=2.7.0 in /usr/local/lib/python3.6/dist-packages (from pymc3->covid19-inference==0.1.8a0) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from pymc3->covid19-inference==0.1.8a0) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->covid19-inference==0.1.8a0) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->covid19-inference==0.1.8a0) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->covid19-inference==0.1.8a0) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->covid19-inference==0.1.8a0) (1.2.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->covid19-inference==0.1.8a0) (2018.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from theano->covid19-inference==0.1.8a0) (1.15.0)\n",
            "Building wheels for collected packages: covid19-inference\n",
            "  Building wheel for covid19-inference (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for covid19-inference: filename=covid19_inference-0.1.8a0-cp36-none-any.whl size=103637 sha256=c9d8f79b296388738bd60cf13e52d5dd4df7a6bb3f29dc6b7f3901d481fd4fe7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ppcxzs9d/wheels/da/f1/e7/da56ba4fe019b70927b4bb10088f02f672b31b69fd54a6e613\n",
            "Successfully built covid19-inference\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaw_BB3ea_DI",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "1.   List item\n",
        "2.   List item\n",
        "\n",
        "\n",
        "\n",
        "# Bayesian Inference of Ghana Covid 19 Data\n",
        "Non-hierarchical model using jhu data.\n",
        "\n",
        "Runtime ~ 15 min\n",
        "\n",
        "The first thing we need to do is import some essential stuff. Theses have to be installed and are prerequisites.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cbbt4TKGa_DQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "import time as time_module\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats\n",
        "import theano\n",
        "import theano.tensor as tt\n",
        "import pymc3 as pm\n",
        "import pickle"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIaH42DFa_Df",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now to the fun stuff, we import our module!\n",
        "try:\n",
        "    import covid19_inference as cov19\n",
        "except ModuleNotFoundError:\n",
        "    sys.path.append(\"../../\")\n",
        "    import covid19_inference as cov19"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5V4Oi8moa_Dt",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Data retrieval \n",
        "\n",
        "> Task a -c\n",
        "\n",
        "- Download the COVID19 case data for your assigned country\n",
        "\n",
        "- Pre-process the downloaded data such that the starting date of the data is when the number of covid19 cases in your country reaches 100 and dominated by a community transmission.\n",
        "\n",
        "- It is unlikely but, if there are dates that have NaN values, perform linear regression to fill these missing values. Make sure the final data has a continuous date - ensure no date is missing. Zero number of cases for a given date is ok.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sHfgXxOLqFr",
        "colab_type": "text"
      },
      "source": [
        "> Use John Hopkins Database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMUxa0F4bXY0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a1d4b2db-35ab-4dd3-c87d-55aa613db2f8"
      },
      "source": [
        "jhu = cov19.data_retrieval.JHU()  # It is important to download the dataset!\n",
        "jhu.download_all_available_data()\n",
        "# One could also parse True to the constructor of the class to force an auto download"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO     [covid19_inference.data_retrieval._JHU] Successfully loaded data from local\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMHDX_wy3eYP",
        "colab_type": "text"
      },
      "source": [
        "### Get total confirmed case for Ghana and its new cases\n",
        "> Ghana recorded its first covid case on 14th of March\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCUYG9lYSd-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bd = datetime.datetime(2020, 3, 14)  # first covid case\n",
        "ed = datetime.datetime.now() "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRdzTrGllXUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_cases_obs = jhu.get_total(\n",
        "    value=\"confirmed\", country=\"Ghana\", data_begin=bd, data_end=ed\n",
        ")\n",
        "new_cases_obs = jhu.get_new(\n",
        "    value=\"confirmed\", country=\"Ghana\", data_begin=bd, data_end=ed\n",
        ")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtCI7dp7lkA9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "267be3a3-4ff9-46c9-c41d-7e7988cf78d5"
      },
      "source": [
        "total_cases_obs"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "date\n",
              "2020-03-14        3\n",
              "2020-03-15        6\n",
              "2020-03-16        6\n",
              "2020-03-17        7\n",
              "2020-03-18        7\n",
              "              ...  \n",
              "2020-08-03    37812\n",
              "2020-08-04    37812\n",
              "2020-08-05    39075\n",
              "2020-08-06    39642\n",
              "2020-08-07    40097\n",
              "Name: confirmed, Length: 147, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmKulQW9lnLZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "38334017-d63d-4c4a-fde3-b30b9ab36c1b"
      },
      "source": [
        "new_cases_obs"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "date\n",
              "2020-03-14       3\n",
              "2020-03-15       3\n",
              "2020-03-16       0\n",
              "2020-03-17       1\n",
              "2020-03-18       0\n",
              "              ... \n",
              "2020-08-03     798\n",
              "2020-08-04       0\n",
              "2020-08-05    1263\n",
              "2020-08-06     567\n",
              "2020-08-07     455\n",
              "Name: confirmed, Length: 147, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDBZRLcUPF-g",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing and Modelling \n",
        "> Task d - f\n",
        "- Split the data into one part used for inference (training set), and an other used for to validate a forecast (validation set):\n",
        "- - Training set includes all dates from the time the community transmission reaches 100 to July 25 2020.\n",
        "- - Validation set includes dates from 25 July 2020 to one final date in the covid19 cases data.  \n",
        "- Plot the training data together with the model that is sampled from the posterior of the SIR model. The posterior of the SIR model means distributions on the Lambda, Mu, and other parameters. A single model curve means a single sample from the posterior distribution.\n",
        "- Use the validation data set to evaluate the forecasting power of the model you generated using the training set. If you are happy with your model, you can run it to make predictions until the 10th of August.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYzMzcr9mBEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set = total_cases_obs[total_cases_obs.index <= '2020-07-25']\n",
        "val_set = new_cases_obs[new_cases_obs.index >= '2020-07-25']\n",
        "new_cases_obs = new_cases_obs[new_cases_obs.index <= '2020-07-25']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgkprrj6b3oa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "f00afe6f-0880-4e07-91d0-b4744e31d2ef"
      },
      "source": [
        "# #cummulative record\n",
        "# ghana_cumm_record = jhu.get_total_confirmed_deaths_recovered(country='Ghana', begin_date= bd, end_date=ed)\n",
        "print(\"Date Has empty row: \",f'{train_set.index.isnull().any()}')\n",
        "train_set"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Date Has empty row:  False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "date\n",
              "2020-03-14        3\n",
              "2020-03-15        6\n",
              "2020-03-16        6\n",
              "2020-03-17        7\n",
              "2020-03-18        7\n",
              "              ...  \n",
              "2020-07-21    28989\n",
              "2020-07-22    29672\n",
              "2020-07-23    29672\n",
              "2020-07-24    31057\n",
              "2020-07-25    31851\n",
              "Name: confirmed, Length: 134, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GYpHoujNAyb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "5594f494-8ccb-4562-c1ca-a3c734c63817"
      },
      "source": [
        "print(\"Date Has empty row: \",f'{val_set.index.isnull().any()}')\n",
        "val_set"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Date Has empty row:  False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "date\n",
              "2020-07-25     794\n",
              "2020-07-26    1118\n",
              "2020-07-27     655\n",
              "2020-07-28     782\n",
              "2020-07-29     736\n",
              "2020-07-30       0\n",
              "2020-07-31     359\n",
              "2020-08-01    1513\n",
              "2020-08-02       0\n",
              "2020-08-03     798\n",
              "2020-08-04       0\n",
              "2020-08-05    1263\n",
              "2020-08-06     567\n",
              "2020-08-07     455\n",
              "Name: confirmed, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCyi_OI7TNCK",
        "colab_type": "text"
      },
      "source": [
        "### Model training and Plotting (before identifying changepoints from the model output)\n",
        "\n",
        "> Prior parameters and Prior Changepoints\n",
        "\n",
        "- pr_delay = 3\n",
        "\n",
        "- population = 31072940\n",
        "\n",
        "- Changepoints \n",
        "\n",
        "`I will start with  just one changepoint here -date when government initiated a partial lockdown policy`  \n",
        "\n",
        "March 30th\n",
        "\n",
        "> I used this date as prior becuase I believe there should be significant changepoint arounf this policy date. But I will test my prior with the posteriors of my model.\n",
        "\n",
        "\n",
        "<!-- > I will compare my model output with validation set to see if there was significant change in the number of cases when the partial lockdown was introduced  -->\n",
        "<!-- \n",
        "`I used these dates as prior becuase I believe there should be significant changepoints arounf these policy dates. But I will test my priors with the posteriors of my model. Note these dates are two days ahead the original dates to accomodate for the delay in effects of changepoints`  -->\n",
        "\n",
        "<!-- > 1. 2020, 3, 30 - partial lockdown\n",
        "2. 2020, 06,  15- ban on major gatherings\n",
        "3. 2020, 07, 26 - restriction on travel -->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTd0eueWa_Ea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "diff_data_sim = 16  # should be significantly larger than the expected delay, in\n",
        "# order to always fit the same number of data points.\n",
        "num_days_forecast = 8"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gyA1t4Ja_Ek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We set the priors for the changepoints here\n",
        "prior_date_mild_dist_begin = datetime.datetime(2020, 3, 30)\n",
        "prior_date_strong_dist_begin = datetime.datetime(2020, 6, 15)\n",
        "prior_date_contact_ban_begin = datetime.datetime(2020, 7, 26)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rsyB8TGa_Eu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "change_points = [\n",
        "    dict(\n",
        "        pr_mean_date_transient=prior_date_mild_dist_begin,\n",
        "        pr_sigma_date_transient=3,\n",
        "        pr_median_lambda=0.2,\n",
        "        pr_sigma_lambda=1,\n",
        "    ),\n",
        "    dict(\n",
        "        pr_mean_date_transient=prior_date_strong_dist_begin,\n",
        "        pr_sigma_date_transient=1.5,\n",
        "        pr_median_lambda=1 / 8,\n",
        "        pr_sigma_lambda=1,\n",
        "    ),\n",
        "    dict(\n",
        "        pr_mean_date_transient=prior_date_contact_ban_begin,\n",
        "        pr_sigma_date_transient=1.5,\n",
        "        pr_median_lambda=1 / 8 / 2,\n",
        "        pr_sigma_lambda=1,\n",
        "    ),\n",
        "]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdW1vk6Fa_E4",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Next, we create the model! There are default values for most of the function arguments,\n",
        "but we will try to explicitly set all kwargs for the sake of this example.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zQajue6a_E6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params_model = dict(\n",
        "    new_cases_obs=train_set[:],\n",
        "    data_begin=bd,\n",
        "    fcast_len=num_days_forecast,\n",
        "    diff_data_sim=diff_data_sim,\n",
        "    N_population=31072940\n",
        ")\n",
        "# Median of the prior for the delay in case reporting, we assume 3 days\n",
        "pr_delay = 3"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ge4wQYlKa_FF",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "The model is specified in a context. Each function in this context\n",
        "has access to the model parameters set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7pkSIpra_FH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "0e10d69c-9344-4e87-ef3a-d867c7a1a78c"
      },
      "source": [
        "with cov19.model.Cov19Model(**params_model) as this_model:\n",
        "    # Create the an array of the time dependent infection rate lambda\n",
        "    lambda_t_log = cov19.model.lambda_t_with_sigmoids(\n",
        "        pr_median_lambda_0=0.4,\n",
        "        pr_sigma_lambda_0=0.5,\n",
        "        change_points_list=change_points,  # The change point priors we constructed earlier\n",
        "        name_lambda_t=\"lambda_t\",  # Name for the variable in the trace (see later)\n",
        "    )\n",
        "\n",
        "    # set prior distribution for the recovery rate\n",
        "    mu = pm.Lognormal(name=\"mu\", mu=np.log(1 / 8), sigma=0.2)\n",
        "\n",
        "    # This builds a decorrelated prior for I_begin for faster inference.\n",
        "    # It is not necessary to use it, one can simply remove it and use the default argument\n",
        "    # for pr_I_begin in cov19.SIR\n",
        "    prior_I = cov19.model.uncorrelated_prior_I(\n",
        "        lambda_t_log=lambda_t_log,\n",
        "        mu=mu,\n",
        "        pr_median_delay=pr_delay,\n",
        "        name_I_begin=\"I_begin\",\n",
        "        name_I_begin_ratio_log=\"I_begin_ratio_log\",\n",
        "        pr_sigma_I_begin=2,\n",
        "        n_data_points_used=5,\n",
        "    )\n",
        "\n",
        "    # Use lambda_t_log and mu to run the SIR model\n",
        "    new_cases = cov19.model.SIR(\n",
        "        lambda_t_log=lambda_t_log,\n",
        "        mu=mu,\n",
        "        name_new_I_t=\"new_I_t\",\n",
        "        name_I_t=\"I_t\",\n",
        "        name_I_begin=\"I_begin\",\n",
        "        pr_I_begin=prior_I,\n",
        "    )\n",
        "\n",
        "    # Delay the cases by a lognormal reporting delay\n",
        "    new_cases = cov19.model.delay_cases(\n",
        "        cases=new_cases,\n",
        "        name_cases=\"delayed_cases\",\n",
        "        name_delay=\"delay\",\n",
        "        name_width=\"delay-width\",\n",
        "        pr_mean_of_median=pr_delay,\n",
        "        pr_sigma_of_median=0.2,\n",
        "        pr_median_of_width=0.3,\n",
        "    )\n",
        "\n",
        "    # Modulate the inferred cases by a abs(sin(x)) function, to account for weekend effects\n",
        "    # Also adds the \"new_cases\" variable to the trace that has all model features.\n",
        "    new_cases = cov19.model.week_modulation(\n",
        "        cases=new_cases,\n",
        "        name_cases=\"new_cases\",\n",
        "        name_weekend_factor=\"weekend_factor\",\n",
        "        name_offset_modulation=\"offset_modulation\",\n",
        "        week_modulation_type=\"abs_sine\",\n",
        "        pr_mean_weekend_factor=0.3,\n",
        "        pr_sigma_weekend_factor=0.5,\n",
        "        weekend_days=(6, 7),\n",
        "    )\n",
        "\n",
        "    # Define the likelihood, uses the new_cases_obs set as model parameter\n",
        "    cov19.model.student_t_likelihood(new_cases)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO     [covid19_inference.model.spreading_rate] Lambda_t with sigmoids\n",
            "INFO     [covid19_inference.model.model] pr_median_transient_len was set to default value 4\n",
            "INFO     [covid19_inference.model.model] pr_sigma_transient_len was set to default value 0.5\n",
            "INFO     [covid19_inference.model.model] relative_to_previous was set to default value False\n",
            "INFO     [covid19_inference.model.model] pr_factor_to_previous was set to default value 1\n",
            "INFO     [covid19_inference.model.model] pr_median_transient_len was set to default value 4\n",
            "INFO     [covid19_inference.model.model] pr_sigma_transient_len was set to default value 0.5\n",
            "INFO     [covid19_inference.model.model] relative_to_previous was set to default value False\n",
            "INFO     [covid19_inference.model.model] pr_factor_to_previous was set to default value 1\n",
            "INFO     [covid19_inference.model.model] pr_median_transient_len was set to default value 4\n",
            "INFO     [covid19_inference.model.model] pr_sigma_transient_len was set to default value 0.5\n",
            "INFO     [covid19_inference.model.model] relative_to_previous was set to default value False\n",
            "INFO     [covid19_inference.model.model] pr_factor_to_previous was set to default value 1\n",
            "INFO     [covid19_inference.model.compartmental_models] Uncorrelated prior_I\n",
            "INFO     [covid19_inference.model.compartmental_models] SIR\n",
            "INFO     [covid19_inference.model.delay] Delaying cases\n",
            "INFO     [covid19_inference.model.week_modulation] Week modulation\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31NlwA3La_FT",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## MCMC sampling\n",
        "\n",
        "After the model is built, it is sampled using an MCMC sampler.\n",
        "The number of parallel runs can be set with the argument `cores=`.\n",
        "In particular, due to a bug in Theano, Windows users should set `cores=1`.\n",
        "The sampling can take a long time.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0-jA2fba_FW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "outputId": "b37f7d4b-73d7-4b43-f579-6f8284960c4f"
      },
      "source": [
        "model1 =  pm.sample(model=this_model, cores=4, tune=50, draws=100, init=\"advi+adapt_diag\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Only 100 samples in chain.\n",
            "WARNING  [pymc3] Only 100 samples in chain.\n",
            "Auto-assigning NUTS sampler...\n",
            "INFO     [pymc3] Auto-assigning NUTS sampler...\n",
            "Initializing NUTS using advi+adapt_diag...\n",
            "INFO     [pymc3] Initializing NUTS using advi+adapt_diag...\n",
            "Average Loss = 1,237.6:  15%|█▌        | 30197/200000 [05:08<28:53, 97.98it/s]\n",
            "Convergence achieved at 30200\n",
            "INFO     [pymc3.variational.inference] Convergence achieved at 30200\n",
            "Interrupted at 30,199 [15%]: Average Loss = 1,520.6\n",
            "INFO     [pymc3.variational.inference] Interrupted at 30,199 [15%]: Average Loss = 1,520.6\n",
            "Multiprocess sampling (4 chains in 4 jobs)\n",
            "INFO     [pymc3] Multiprocess sampling (4 chains in 4 jobs)\n",
            "NUTS: [sigma_obs, offset_modulation_rad, weekend_factor_log, delay_log, I_begin_ratio_log, mu, transient_len_3_log_, transient_len_2_log_, transient_len_1_log_, transient_day_3, transient_day_2, transient_day_1, lambda_3_log_, lambda_2_log_, lambda_1_log_, lambda_0_log_]\n",
            "INFO     [pymc3] NUTS: [sigma_obs, offset_modulation_rad, weekend_factor_log, delay_log, I_begin_ratio_log, mu, transient_len_3_log_, transient_len_2_log_, transient_len_1_log_, transient_day_3, transient_day_2, transient_day_1, lambda_3_log_, lambda_2_log_, lambda_1_log_, lambda_0_log_]\n",
            "Sampling 4 chains: 100%|██████████| 600/600 [1:04:13<00:00,  6.42s/draws]\n",
            "The acceptance probability does not match the target. It is 0.9715690515237141, but should be close to 0.8. Try to increase the number of tuning steps.\n",
            "WARNING  [pymc3] The acceptance probability does not match the target. It is 0.9715690515237141, but should be close to 0.8. Try to increase the number of tuning steps.\n",
            "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
            "WARNING  [pymc3] The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
            "The acceptance probability does not match the target. It is 0.8883596432943158, but should be close to 0.8. Try to increase the number of tuning steps.\n",
            "WARNING  [pymc3] The acceptance probability does not match the target. It is 0.8883596432943158, but should be close to 0.8. Try to increase the number of tuning steps.\n",
            "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
            "WARNING  [pymc3] The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
            "The acceptance probability does not match the target. It is 0.9098590015454974, but should be close to 0.8. Try to increase the number of tuning steps.\n",
            "WARNING  [pymc3] The acceptance probability does not match the target. It is 0.9098590015454974, but should be close to 0.8. Try to increase the number of tuning steps.\n",
            "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
            "WARNING  [pymc3] The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
            "The acceptance probability does not match the target. It is 0.441817596150418, but should be close to 0.8. Try to increase the number of tuning steps.\n",
            "WARNING  [pymc3] The acceptance probability does not match the target. It is 0.441817596150418, but should be close to 0.8. Try to increase the number of tuning steps.\n",
            "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
            "WARNING  [pymc3] The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
            "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
            "ERROR    [pymc3] The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
            "The number of effective samples is smaller than 10% for some parameters.\n",
            "WARNING  [pymc3] The number of effective samples is smaller than 10% for some parameters.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZJz94qz5hdg",
        "colab_type": "text"
      },
      "source": [
        "Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSPijCF4K22B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To mount the Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')#To Save the trace results to a pickle file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahob-RP-5hBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle_out = open(\"model1.pickle\",\"wb\")\n",
        "pickle.dump(model1, pickle_out)\n",
        "pickle_out.close()\n",
        "#When it saves, look in the navigation pane on your left, you will see the trace.pickle file there, download it to your hard drive and every time you run a google colab instance, you can upload it #To load the file from pickle\n",
        "pickle_in = open(\"model1.pickle\",\"rb\")\n",
        "model1= pickle.load(pickle_in)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY2iq3-0a_Ff",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Plotting\n",
        "Plotting tools are rudimentary right now. But one can always write custom plotting function\n",
        "by accessing the samples stored in the trace.\n",
        "\n",
        "### Distributions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "mj23HiF4a_Fh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axes = plt.subplots(6, 3, figsize=(6, 6.4))\n",
        "varnames = varnames = this_model.free_RVs #this_model.untransformed_freeRVs\n",
        "print(\"Possible varnames are :\")\n",
        "print(varnames)\n",
        "for i, key in enumerate(\n",
        "    # left column\n",
        "    [\"weekend_factor\", \"mu\", \"lambda_0\", \"lambda_1\"] #\"lambda_2\", \"lambda_3\"]\n",
        "):\n",
        "    cov19.plot._distribution(this_model, model1, key, ax=axes[i, 0]) #replcae trace with model1\n",
        "for i, key in enumerate(\n",
        "    # mid column\n",
        "    [\n",
        "        \"offset_modulation\",\n",
        "        \"sigma_obs\",\n",
        "        \"I_begin\",\n",
        "        \"transient_day_1\",\n",
        "        #\"transient_day_2\",\n",
        "        #\"transient_day_3\",\n",
        "    ]\n",
        "):\n",
        "    cov19.plot._distribution(this_model, model1, key, ax=axes[i, 1])\n",
        "for i, key in enumerate(\n",
        "    # right column\n",
        "    [\"delay\", \"transient_len_1\"] #\"transient_len_2\", \"transient_len_3\",]\n",
        "):\n",
        "    cov19.plot._distribution(this_model, model1, key, ax=axes[i + 2, 2])\n",
        "fig.tight_layout()\n",
        "fig #To print in jupyter notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcQ8kJPAa_GU",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Timeseries\n",
        "timeseries overview, for now needs an offset variable to get cumulative cases\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXmFQzr3a_GW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axes = cov19.plot.timeseries_overview(this_model, model1, offset=3000)#ghana_covid_100[0])\n",
        "plt.savefig(fname=\"timeseries_model1.png\", format='png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIP8kZx4KlI1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}